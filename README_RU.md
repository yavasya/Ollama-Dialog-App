
# Ollama AI Interactor (Ollama-Dialog-App)

Веб-приложение на Flask, предназначенное для организации и управления **диалогом между двумя языковыми моделями Ollama**. Это не инструмент сравнения, а скорее песочница для наблюдения за взаимодействием и совместной работой ИИ.

Пользователь инициирует тему разговора, после чего модели обмениваются репликами в автоматическом или ручном режиме, динамически меняясь ролями "пользователь" и "ассистент" в каждом ходе.

## Ключевые возможности

*   **Автоматизированный диалог ИИ:** Наблюдайте, как две модели общаются друг с другом на заданную вами тему.
*   **Динамическая смена ролей:** Каждая модель по очереди получает историю диалога и воспринимает ответ предыдущей модели как "запрос пользователя", создавая непрерывную беседу.
*   **Управление "на лету":** Возможность менять системные промпты (инструкции) и даже сами модели *во время* идущего диалога.
*   **Логирование отладки:** Детальное окно логов показывает точные сообщения и промпты, отправляемые на сервер Ollama.

## Примеры использования

*   **Совместное творчество:** Наблюдайте, как ИИ совместно пишут код, истории или решают задачи.
*   **Тестирование промптов:** Быстро проверяйте, как разные системные инструкции влияют на ход беседы.
*   **Исследование поведения моделей:** Изучайте, как модели реагируют друг на друга без участия человека.

---

[Read in English](README.md)

---

## Технологии

*   **Backend:** Python, Flask
*   **LLM Runtime:** Ollama
*   **Frontend:** HTML, CSS, JavaScript (для динамики чата)

## Установка и запуск

Чтобы запустить этот проект локально, выполните следующие шаги:

### 1. Установите Ollama

Убедитесь, что у вас установлен Ollama и он запущен в фоновом режиме. Вы можете скачать его с официального сайта:

[www.ollama.com](www.ollama.com)

### 2. Загрузите необходимые модели

Используйте команду `ollama pull` в вашем терминале, чтобы загрузить модели, которые вы хотите сравнивать (например, те, что на скриншоте):

```bash
ollama pull mistral-nemo:latest
ollama pull gemma3:12b


